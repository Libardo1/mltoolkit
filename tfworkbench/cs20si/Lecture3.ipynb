{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lecture 3: Linear and Logistic Regression\n",
    "\n",
    "http://web.stanford.edu/class/cs20si/lectures/slides_03.pdf\n",
    "\n",
    "Simple linear regression example in TensorFlow\n",
    "This program tries to predict the number of thefts from \n",
    "the number of fire in the city of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All imports\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "from util import newlogname\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/fire_theft.xls'\n",
    "\n",
    "# Phase 1: Assemble the graph\n",
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override='utf-8')\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size =  42\n",
      "\n",
      "First 5 observations of the dataset:\n",
      "\n",
      "[[  6.2  29. ]\n",
      " [  9.5  44. ]\n",
      " [ 10.5  36. ]\n",
      " [  7.7  37. ]\n",
      " [  8.6  53. ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size = \", len(data))\n",
    "print(\"\\nFirst 5 observations of the dataset:\\n\")\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model, i.e., the graph and the session for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(log_path, lr=0.001,loss_function=None):\n",
    "    \n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        # Step 2: create placeholders for input X (number of fire) and label Y (number of theft)\n",
    "\n",
    "        number_fire = tf.placeholder(tf.float32,shape=[],name=\"X\")\n",
    "        number_theft = tf.placeholder(tf.float32,shape=[],name=\"Y\")\n",
    "\n",
    "\n",
    "        # Step 3: create weight and bias, initialized to 0\n",
    "        # name your variables w and b\n",
    "        with tf.name_scope(\"Weights\"):\n",
    "            weight = tf.get_variable(\"w\",dtype=tf.float32,initializer=0.)\n",
    "            bias = tf.get_variable(\"b\",dtype=tf.float32,initializer=0.)\n",
    "            tf.summary.histogram('weights_summ',weight)\n",
    "            tf.summary.histogram('bias_summ',bias)\n",
    "\n",
    "        # Step 4: predict Y (number of theft) from the number of fire\n",
    "        # name your variable Y_predicted\n",
    "        with tf.name_scope(\"linear-model\"):\n",
    "            Y_predicted = (number_fire*weight) + bias \n",
    "\n",
    "        # Step 5: use the square error as the loss function\n",
    "        # name your variable loss\n",
    "        with tf.name_scope(\"loss-fuction\"):\n",
    "            if loss_function is None:\n",
    "                loss = tf.pow((Y_predicted -number_theft),2)\n",
    "            else:\n",
    "                loss = loss_function(number_theft, Y_predicted)\n",
    "            tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "        # Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "\n",
    "    # Phase 2: Train our model\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        print(\"\\n ==Beggining training for lr={}==\".format(lr))\n",
    "        summary_writer = tf.summary.FileWriter(log_path,sess.graph)\n",
    "        all_summaries = tf.summary.merge_all() \n",
    "        # Step 7: initialize the necessary variables, in this case, w and b\n",
    "        tf.global_variables_initializer().run()\n",
    "        # Step 8: train the model\n",
    "        step = 0\n",
    "        total_steps = len(data)*100\n",
    "        for i in range(100): # run 100 epochs\n",
    "            total_loss = 0\n",
    "            for x, y in data:\n",
    "                # Session runs optimizer to minimize loss and fetch the value of loss\n",
    "                step += 1\n",
    "                feed_dict = {number_fire:x, number_theft:y}\n",
    "                _,l,summary,w,b = sess.run([optimizer,loss,all_summaries, weight,bias], feed_dict=feed_dict)\n",
    "\n",
    "                #writing the log\n",
    "                summary_writer.add_summary(summary,step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                total_loss += l\n",
    "                # sys.stdout.write('\\r{} / {} : pp = {}'.format(step, total_steps,total_loss))\n",
    "                # sys.stdout.flush()\n",
    "            if i%10==0:\n",
    "                print(\"\\nEpoch {0}: {1}\".format(i, total_loss/n_samples))\n",
    "    return total_loss,w,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After defined the model we can run different trainings with different learning rates to check which one is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==Beggining training for lr=0.0009==\n",
      "\n",
      "Epoch 0: 1775.2119261437938\n",
      "\n",
      "Epoch 10: 1653.5637995948393\n",
      "\n",
      "Epoch 20: 1537.7932460307466\n",
      "\n",
      "Epoch 30: 1454.4950013958983\n",
      "\n",
      "Epoch 40: 1393.7797238769099\n",
      "\n",
      "Epoch 50: 1349.005913916798\n",
      "\n",
      "Epoch 60: 1315.6468483918745\n",
      "\n",
      "Epoch 70: 1290.5730496667647\n",
      "\n",
      "Epoch 80: 1271.584222030216\n",
      "\n",
      "Epoch 90: 1257.114225530997\n",
      "\n",
      " ==Beggining training for lr=0.00087==\n",
      "\n",
      "Epoch 0: 1696.1530765706584\n",
      "\n",
      "Epoch 10: 1578.6739477940969\n",
      "\n",
      "Epoch 20: 1472.5063404076334\n",
      "\n",
      "Epoch 30: 1395.6836117442165\n",
      "\n",
      "Epoch 40: 1339.392999981131\n",
      "\n",
      "Epoch 50: 1297.6737101645697\n",
      "\n",
      "Epoch 60: 1266.4380452441746\n",
      "\n",
      "Epoch 70: 1242.84422111412\n",
      "\n",
      "Epoch 80: 1224.8863509127737\n",
      "\n",
      "Epoch 90: 1211.13078761562\n",
      "\n",
      " ==Beggining training for lr=0.00075==\n",
      "\n",
      "Epoch 0: 1421.2475874310448\n",
      "\n",
      "Epoch 10: 1310.3567895946048\n",
      "\n",
      "Epoch 20: 1237.2140785129297\n",
      "\n",
      "Epoch 30: 1183.1046448818274\n",
      "\n",
      "Epoch 40: 1142.6468263798909\n",
      "\n",
      "Epoch 50: 1112.0881879467163\n",
      "\n",
      "Epoch 60: 1088.786351671531\n",
      "\n",
      "Epoch 70: 1070.8637784969594\n",
      "\n",
      "Epoch 80: 1056.970183225526\n",
      "\n",
      "Epoch 90: 1046.1249517906413\n",
      "\n",
      " ==Beggining training for lr=0.0012==\n",
      "\n",
      "Epoch 0: 2798.7882986820878\n",
      "\n",
      "Epoch 10: 2558.050653090789\n",
      "\n",
      "Epoch 20: 2319.9042597657867\n",
      "\n",
      "Epoch 30: 2158.4893718488247\n",
      "\n",
      "Epoch 40: 2047.289945574034\n",
      "\n",
      "Epoch 50: 1969.657730367829\n",
      "\n",
      "Epoch 60: 1914.881513392996\n",
      "\n",
      "Epoch 70: 1875.9099566485024\n",
      "\n",
      "Epoch 80: 1848.0066623013645\n",
      "\n",
      "Epoch 90: 1827.9310916935403\n",
      "\n",
      " ==Beggining training for lr=0.002==\n",
      "\n",
      "Epoch 0: 9782.668905170824\n",
      "\n",
      "Epoch 10: 8794.69655057591\n",
      "\n",
      "Epoch 20: 8057.033727129832\n",
      "\n",
      "Epoch 30: 7588.161024927561\n",
      "\n",
      "Epoch 40: 7286.327502750215\n",
      "\n",
      "Epoch 50: 7090.301954767002\n",
      "\n",
      "Epoch 60: 6962.210527918434\n",
      "\n",
      "Epoch 70: 6878.1689040756655\n",
      "\n",
      "Epoch 80: 6822.86450138759\n",
      "\n",
      "Epoch 90: 6786.412504922776\n",
      "\n",
      "the best lr is 0.00075, with loss = 1038.3717856426679\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.0009,0.00087,0.00075,0.0012,0.002]\n",
    "best_loss = float('inf')\n",
    "best_lr = 0\n",
    "w = 0\n",
    "b = 0 \n",
    "for lr in all_lr:\n",
    "    path_log = './graphs/' + str(lr)\n",
    "    current_loss,current_w, current_b = linear_regression(path_log,lr)\n",
    "    if current_loss < best_loss:\n",
    "        best_loss, best_lr = current_loss, lr\n",
    "        w, b = current_w, current_b\n",
    "print(\"\\nthe best lr is {0}, with loss = {1}\".format(best_lr,best_loss/n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ploting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f769c7e69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w + b, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now we can use tensorboad to see witch one is the best hyper param. For doing so, we need to set loogdir to the parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=./graphs --port=8008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber loss\n",
    "\n",
    "Robust to outliers\n",
    "\n",
    "Intuition: if the difference between the predicted value and the real value is small, square it If it’s large, take its absolute value\n",
    "\n",
    "   \n",
    "- $L_{\\delta}(y,f(x)) =  \\frac{1}{2}(y-f(x))^{2}$ if $|y-f(x)|\\leq \\delta$\n",
    "\n",
    "- $L_{\\delta}(y,f(x)) =  \\delta|y-f(x)| -\\frac{1}{2}\\delta^{2}$ otherwise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implementing Huber loss in tf\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.where(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now repeating the training with Huber loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==Beggining training for lr=0.0009==\n",
      "\n",
      "Epoch 0: 30.5058015641712\n",
      "\n",
      "Epoch 10: 16.53957552613602\n",
      "\n",
      "Epoch 20: 16.472495969917095\n",
      "\n",
      "Epoch 30: 16.40623512354103\n",
      "\n",
      "Epoch 40: 16.341193102898874\n",
      "\n",
      "Epoch 50: 16.27731665216076\n",
      "\n",
      "Epoch 60: 16.213774049571448\n",
      "\n",
      "Epoch 70: 16.15062386205786\n",
      "\n",
      "Epoch 80: 16.08786667798094\n",
      "\n",
      "Epoch 90: 16.025500217763085\n",
      "\n",
      " ==Beggining training for lr=0.00087==\n",
      "\n",
      "Epoch 0: 30.588147572108678\n",
      "\n",
      "Epoch 10: 16.53861704273593\n",
      "\n",
      "Epoch 20: 16.473600614283765\n",
      "\n",
      "Epoch 30: 16.409472711428645\n",
      "\n",
      "Epoch 40: 16.34647723934835\n",
      "\n",
      "Epoch 50: 16.284601737523364\n",
      "\n",
      "Epoch 60: 16.223123986124328\n",
      "\n",
      "Epoch 70: 16.161989735882905\n",
      "\n",
      "Epoch 80: 16.10121916447367\n",
      "\n",
      "Epoch 90: 16.04081069217119\n",
      "\n",
      " ==Beggining training for lr=0.00075==\n",
      "\n",
      "Epoch 0: 30.917532228288195\n",
      "\n",
      "Epoch 10: 16.610250842896114\n",
      "\n",
      "Epoch 20: 16.47840994507784\n",
      "\n",
      "Epoch 30: 16.4228663751412\n",
      "\n",
      "Epoch 40: 16.368149911408267\n",
      "\n",
      "Epoch 50: 16.31424934665362\n",
      "\n",
      "Epoch 60: 16.261060962231742\n",
      "\n",
      "Epoch 70: 16.208056159289775\n",
      "\n",
      "Epoch 80: 16.155315083091235\n",
      "\n",
      "Epoch 90: 16.102832949631626\n",
      "\n",
      " ==Beggining training for lr=0.0012==\n",
      "\n",
      "Epoch 0: 29.682338124229794\n",
      "\n",
      "Epoch 10: 16.548284386417695\n",
      "\n",
      "Epoch 20: 16.459121220168612\n",
      "\n",
      "Epoch 30: 16.371940078147286\n",
      "\n",
      "Epoch 40: 16.28692226978906\n",
      "\n",
      "Epoch 50: 16.202607181546878\n",
      "\n",
      "Epoch 60: 16.119070987312064\n",
      "\n",
      "Epoch 70: 16.036378647339355\n",
      "\n",
      "Epoch 80: 15.953119378758682\n",
      "\n",
      "Epoch 90: 15.86987965326712\n",
      "\n",
      " ==Beggining training for lr=0.002==\n",
      "\n",
      "Epoch 0: 27.486436344328382\n",
      "\n",
      "Epoch 10: 16.50884522411174\n",
      "\n",
      "Epoch 20: 16.343268686184835\n",
      "\n",
      "Epoch 30: 16.194900147680613\n",
      "\n",
      "Epoch 40: 16.05619309103072\n",
      "\n",
      "Epoch 50: 15.924801669482674\n",
      "\n",
      "Epoch 60: 15.802057752297038\n",
      "\n",
      "Epoch 70: 15.682360045772622\n",
      "\n",
      "Epoch 80: 15.563051126653416\n",
      "\n",
      "Epoch 90: 15.426781277139005\n",
      "\n",
      "the best lr is 0.002, with loss = 15.268346142910776\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.0009,0.00087,0.00075,0.0012,0.002]\n",
    "best_loss = float('inf')\n",
    "best_lr = 0\n",
    "w = 0\n",
    "b = 0 \n",
    "for lr in all_lr:\n",
    "    path_log = './graphs/' + str(lr)\n",
    "    current_loss,current_w, current_b = linear_regression(path_log,lr,huber_loss)\n",
    "    if current_loss < best_loss:\n",
    "        best_loss, best_lr = current_loss, lr\n",
    "        w, b = current_w, current_b\n",
    "print(\"\\nthe best lr is {0}, with loss = {1}\".format(best_lr,best_loss/n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76947336a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w + b, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder data/mnist\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "def logistic_regression(lr=0.01,batch_size=128,n_epochs=10,log_path=None):\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Step 2: create placeholders for features and labels\n",
    "        # each image in the MNIST data is of shape 28*28 = 784\n",
    "        # therefore, each image is represented with a 1x784 tensor\n",
    "        # there are 10 classes for each image, corresponding to digits 0 - 9.\n",
    "\n",
    "        X = tf.placeholder(tf.float32,shape=(batch_size ,784), name=\"X\")\n",
    "        Y = tf.placeholder(tf.float32, shape=(batch_size, num_classes), name=\"Y\")\n",
    "\n",
    "        # Step 3: create weights and bias\n",
    "        # weights and biases are initialized to 0\n",
    "        # shape of w depends on the dimension of X and Y so that Y = X * w + b\n",
    "        # shape of b depends on Y\n",
    "\n",
    "        with tf.name_scope(\"Weights\"):\n",
    "            w_shape = (784,num_classes)\n",
    "            b_shape = (num_classes)\n",
    "            w_init = tf.zeros(w_shape)\n",
    "            b_init = tf.zeros(b_shape)\n",
    "            weight = tf.get_variable(\"w\",dtype=tf.float32,initializer=w_init)\n",
    "            bias = tf.get_variable(\"b\",dtype=tf.float32,initializer=b_init)\n",
    "            tf.summary.histogram('weights_summ',weight)\n",
    "            tf.summary.histogram('bias_summ',bias)\n",
    "\n",
    "\n",
    "        # Step 4: build model\n",
    "        # the model that returns the logits.\n",
    "        # this logits will be later passed through softmax layer\n",
    "        # to get the probability distribution of possible label of the image\n",
    "        # DO NOT DO SOFTMAX HERE\n",
    "\n",
    "        with tf.name_scope(\"Linear_layer\"):\n",
    "            logits = tf.add(tf.matmul(X,weight),bias,name=\"logits\")\n",
    "\n",
    "        # Step 5: define loss function\n",
    "        # use cross entropy loss of the real labels with the softmax of logits\n",
    "        # use the method:\n",
    "        # tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n",
    "        # then use tf.reduce_mean to get the mean loss of the batch\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "            tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "\n",
    "        # Step 6: define training op\n",
    "        # using gradient descent to minimize loss\n",
    "\n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "            \n",
    "    if log_path is None:\n",
    "        log_path = newlogname()\n",
    "        print(\"\\n&&&&&log_path={}&&&&&\".format(log_path))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        print(\"\\n==Beggining training for lr={0}, batch_size={1} and n_epochs={2}==\".format(lr,batch_size,n_epochs))\n",
    "        summary_writer = tf.summary.FileWriter(log_path,sess.graph)\n",
    "        all_summaries = tf.summary.merge_all() \n",
    "        start_time = time.time()\n",
    "        sess.run(tf.global_variables_initializer())\t\n",
    "        n_batches = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(n_epochs): # train the model n_epochs times\n",
    "            total_loss = 0\n",
    "            for _ in range(n_batches):\n",
    "                X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "                feed_dict = {X: X_batch, Y: Y_batch}\n",
    "                _,loss_batch,summary = sess.run([optimizer,loss,all_summaries], feed_dict=feed_dict)\n",
    "                total_loss += loss_batch\n",
    "            print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "\n",
    "        print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "        print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "        # test the model\n",
    "        n_batches = int(mnist.test.num_examples/batch_size)\n",
    "        total_correct_preds = 0\n",
    "        for i in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "            _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "            preds = tf.nn.softmax(logits_batch)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "        print('Accuracy {0}/{1} ={2}'.format(total_correct_preds,mnist.test.num_examples,total_correct_preds/mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "&&&&&log_path=./graphs/03-03-2017_21-47-08&&&&&\n",
      "\n",
      "==Beggining training for lr=0.01, batch_size=128 and n_epochs=10==\n",
      "Average loss epoch 0: 1.2884496112803479\n",
      "Average loss epoch 1: 0.7328035713353634\n",
      "Average loss epoch 2: 0.6008441435012506\n",
      "Average loss epoch 3: 0.5368735335228882\n",
      "Average loss epoch 4: 0.49813148302909654\n",
      "Average loss epoch 5: 0.4712426028190515\n",
      "Average loss epoch 6: 0.45082001016412304\n",
      "Average loss epoch 7: 0.43598701869135414\n",
      "Average loss epoch 8: 0.4227202563852697\n",
      "Average loss epoch 9: 0.4121868123402407\n",
      "Total time: 7.2182886600494385 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 112.0/10000 =0.0112\n"
     ]
    }
   ],
   "source": [
    "logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
