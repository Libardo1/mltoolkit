{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "from __future__ import print_function\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from six.moves import range\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and reshape it in a 4 dimension tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28, 1) (200000, 10)\n",
      "Validation: (10000, 28, 28, 1) (10000, 10)\n",
      "Testing: (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "# reformating the dataset to be a 4 dimension tensor\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nogDaGSqKogDaGSqKogDw/9J4+MjMp0xcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a1d8d1c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "#getting the classes from the one-hot-labels\n",
    "train_classes = np.argmax(train_labels, axis=1)\n",
    "train_classes = [chr(i +ord('A')) for i in train_classes]\n",
    "\n",
    "# the images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Get the first images from the test-set.\n",
    "images = train_dataset[10:19]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = train_classes[10:19]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)  \n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#function that performs the weights bias initialization  \n",
    "def init_weights_biases(shape,weights_name,biases_name):\n",
    "    layer = {\\\n",
    "        'weights':tf.Variable(tf.truncated_normal(shape, stddev=0.1),name=weights_name),\n",
    "        'biases':tf.Variable(tf.zeros(shape[-1]),name=biases_name)}\n",
    "    return layer\n",
    "\n",
    "\n",
    "#function that performs the Xavier initialization  \n",
    "def Xa_init_weights_biases(V_shape,weights_name,biases_name):\n",
    "    layer = {\\\n",
    "        'weights':tf.get_variable(weights_name, shape=V_shape,\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'biases':tf.Variable(tf.zeros(V_shape[-1]),name=biases_name)}\n",
    "    return layer\n",
    "\n",
    "#linear function of layer layer using data as input \n",
    "def linear_activation(data,layer):\n",
    "    return tf.add(tf.matmul(data, layer['weights'], name = 'multiply'),\\\n",
    "      layer['biases'],name ='add')  \n",
    "\n",
    "#L2 regularization\n",
    "def L2(beta,layer):\n",
    "    return tf_beta*tf.nn.l2_loss(layer['weights'])\n",
    "\n",
    "\n",
    "#funtion that given the dataset shape X and targets shape Y, returns\n",
    "#two placeholders for the SGD\n",
    "def init_placeholders(shape_X,shape_Y,name_X,name_Y):\n",
    "    X = tf.placeholder(tf.float32, shape =shape_X ,name = name_X)\n",
    "    Y = tf.placeholder(tf.float32, shape=shape_Y, name = name_Y)\n",
    "    return X,Y\n",
    "\n",
    "#initialization of a otimizer (SGD) with exponential decay\n",
    "def sgd_train(error, starter_learning_rate,steps_for_decay,decay_rate):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(\\\n",
    "                starter_learning_rate,\\\n",
    "                global_step,\\\n",
    "                steps_for_decay,\\\n",
    "                decay_rate, staircase=True)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    return optimizer.minimize(error, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to creat a convolutional layer with max pooling\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input,\n",
    "                   layer,\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    weights = layer['weights']\n",
    "    biases = layer['biases']\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    conv_layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    conv_layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        conv_layer = tf.nn.max_pool(value=conv_layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model: \n",
    "---\n",
    "2 convolutional layers and 4 connected layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def network(\\\n",
    "            data,\\\n",
    "            V_hidden_layer_1,\\\n",
    "            V_hidden_layer_2,\\\n",
    "            V_hidden_layer_3,\\\n",
    "            V_hidden_layer_4,\\\n",
    "            V_hidden_layer_5,\\\n",
    "            V_hidden_layer_6):\n",
    "    with tf.name_scope('Convolution_1'):\n",
    "        conv_layer1 = new_conv_layer(data,V_hidden_layer_1,use_pooling=True)\n",
    "    with tf.name_scope('Convolution_2'):\n",
    "        conv_layer2 = new_conv_layer(conv_layer1,V_hidden_layer_2,use_pooling=True)\n",
    "    with tf.name_scope('Reshape'):\n",
    "        shape = conv_layer2.get_shape().as_list() \n",
    "        reshape = tf.reshape(conv_layer2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    with tf.name_scope('Hidden_Layer_1'):\n",
    "        hidden_la1 = tf.nn.relu(linear_activation(reshape,V_hidden_layer_3)) \n",
    "    with tf.name_scope('Hidden_Layer_2'):\n",
    "        hidden_la2 = tf.sigmoid(linear_activation(hidden_la1,V_hidden_layer_4))\n",
    "    with tf.name_scope('Hidden_Layer_3'):\n",
    "        hidden_la3 = tf.sigmoid(linear_activation(hidden_la2,V_hidden_layer_5))     \n",
    "    with tf.name_scope('Output_Layer'):\n",
    "        logits = linear_activation(hidden_la3,V_hidden_layer_6) \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow graph\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "patch_size = 6\n",
    "filters_1 = 16\n",
    "filters_2 = 32\n",
    "hidden_nodes_1 = 60\n",
    "hidden_nodes_2 = 40\n",
    "hidden_nodes_3 = 20\n",
    "\n",
    "\n",
    "graph = tf.Graph() \n",
    "with graph.as_default():\n",
    "    \n",
    "    #Placeholders for the SGD.\n",
    "    tf_train_dataset, tf_train_labels  = init_placeholders(\\\n",
    "                                            (batch_size, image_size,image_size, num_channels),\\\n",
    "                                            (batch_size, num_labels),'X','Y')\n",
    "\n",
    "    #constants: we use then to see accuracity of the network\n",
    "    tf_valid_dataset = tf.constant(valid_dataset, name ='X_va')\n",
    "    tf_test_dataset = tf.constant(test_dataset, name ='X_test')\n",
    "\n",
    "    #constant for the L2 regularization \n",
    "    tf_beta = tf.constant(0.005)\n",
    "    \n",
    "      \n",
    "    #hidden layer 1 - normal initialization \n",
    "    tf_hidden_layer_1 = init_weights_biases(\\\n",
    "                    [patch_size, patch_size, num_channels, filters_1],\n",
    "                    \"weights1\",'biases1')\n",
    "\n",
    "    #hidden layer 2 - normal initialization \n",
    "    tf_hidden_layer_2 = init_weights_biases(\\\n",
    "                [patch_size, patch_size, filters_1, filters_2],\n",
    "                \"weights2\",'biases2')\n",
    "    \n",
    "    #hidden layer 3 - Xavier initialization\n",
    "    tf_hidden_layer_3 = init_weights_biases(\\\n",
    "                    [image_size // 4 * image_size // 4 * filters_2, hidden_nodes_1],\n",
    "                    \"weights3\",'biases3')\n",
    "\n",
    "\n",
    "    #hidden layer 4 - Xavier initialization \n",
    "    tf_hidden_layer_4 = init_weights_biases(\\\n",
    "                [hidden_nodes_1, hidden_nodes_2],\n",
    "                \"weights4\",'biases4')\n",
    "    \n",
    "    #hidden layer 5 - normal initialization \n",
    "    tf_hidden_layer_5 = init_weights_biases(\\\n",
    "                [hidden_nodes_2, hidden_nodes_3],\n",
    "                \"weights5\",'biases5')\n",
    "    \n",
    "    \n",
    "    #hidden layer 6 - normal initialization \n",
    "    tf_hidden_layer_6 = init_weights_biases(\\\n",
    "                [hidden_nodes_3, num_labels],\n",
    "                \"weights6\",'biases6')  \n",
    "    \n",
    "    #histogram summaries for weights\n",
    "    tf.summary.histogram('weights1_summ',tf_hidden_layer_1['weights'])\n",
    "    tf.summary.histogram('weights2_summ',tf_hidden_layer_2['weights'])\n",
    "    tf.summary.histogram('weights3_summ',tf_hidden_layer_3['weights'])\n",
    "    tf.summary.histogram('weights4_summ',tf_hidden_layer_4['weights'])\n",
    "    tf.summary.histogram('weights5_summ',tf_hidden_layer_5['weights'])\n",
    "    tf.summary.histogram('weights6_summ',tf_hidden_layer_6['weights'])\n",
    "        \n",
    "    #the NN with the train dataset\n",
    "    logits = network(\\\n",
    "                     tf_train_dataset,\\\n",
    "                     tf_hidden_layer_1,\\\n",
    "                     tf_hidden_layer_2,\\\n",
    "                     tf_hidden_layer_3,\\\n",
    "                     tf_hidden_layer_4,\\\n",
    "                     tf_hidden_layer_5,\\\n",
    "                     tf_hidden_layer_6)\n",
    "\n",
    "    #the NN with the valid dataset\n",
    "    valid_network = network(\\\n",
    "                    tf_valid_dataset,\\\n",
    "                    tf_hidden_layer_1,\\\n",
    "                    tf_hidden_layer_2,\\\n",
    "                    tf_hidden_layer_3,\\\n",
    "                    tf_hidden_layer_4,\\\n",
    "                    tf_hidden_layer_5,\\\n",
    "                    tf_hidden_layer_6)\n",
    "    \n",
    "    #the NN with the test dataset\n",
    "    test_network = network(\\\n",
    "                    tf_test_dataset,\\\n",
    "                    tf_hidden_layer_1,\\\n",
    "                    tf_hidden_layer_2,\\\n",
    "                    tf_hidden_layer_3,\\\n",
    "                    tf_hidden_layer_4,\\\n",
    "                    tf_hidden_layer_5,\\\n",
    "                    tf_hidden_layer_6)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "      loss = tf.reduce_mean(\\\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_train_labels))\\\n",
    "        #+ L2(tf_beta,tf_hidden_layer_1)\\\n",
    "        #+ L2(tf_beta,tf_hidden_layer_2)\\\n",
    "        #+ L2(tf_beta,tf_hidden_layer_3)\\\n",
    "        #+ L2(tf_beta,tf_hidden_layer_4)\n",
    "      tf.summary.scalar(loss.op.name,loss) #write loss to log\n",
    "\n",
    "    #Optimizer.\n",
    "    with tf.name_scope('training'):\n",
    "        optimizer = sgd_train(loss, 0.9,100,0.96)    \n",
    "    #with tf.name_scope('training'):\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    #applying the softmax function on the \n",
    "    #network with the train, valid,\n",
    "    #and test datasets, respectively.       \n",
    "    train_prediction = tf.nn.softmax(logits, name='train_network')\n",
    "    train_pred_cls = tf.argmax(train_prediction, dimension=1)\n",
    "    valid_prediction = tf.nn.softmax(valid_network, name='valid_network')\n",
    "    test_prediction = tf.nn.softmax(test_network, name='test_network')\n",
    "\n",
    "    #Minibatch accuracy\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_pred = tf.equal(tf.argmax(train_prediction, 1), tf.argmax(tf_train_labels, 1))\n",
    "        acc_op = tf.reduce_mean(tf.cast(correct_pred,'float'))\n",
    "        tf.summary.scalar(acc_op.op.name,acc_op) #write acc to log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Session\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "(128, 28, 28, 1)\n",
      "(128, 10)\n",
      "Minibatch loss at step 0: 2.331510\n",
      "Minibatch accuracy: 5.47%\n"
     ]
    }
   ],
   "source": [
    "#direction for the writer to log\n",
    "log_basedir = 'logs'\n",
    "run_label = time.strftime('%d-%m-%Y_%H-%M-%S') #e.g. 12-11-2016_18-20-45\n",
    "log_path = os.path.join(log_basedir,run_label)\n",
    "\n",
    "num_steps = 1\n",
    "\n",
    "initial_time = time.time()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  summary_writer = tf.summary.FileWriter(log_path, session.graph) \n",
    "  all_summaries = tf.summary.merge_all() \n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "   \n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    print(batch_data.shape)\n",
    "    print(batch_labels.shape)\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    #we are going to run the session and count the duration of the running\n",
    "    start_time = time.time()\n",
    "    _, l, predictions, acc, summary = session.run(\n",
    "      [optimizer, loss, train_prediction, acc_op, all_summaries], feed_dict=feed_dict)\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    #writing the log\n",
    "    summary_writer.add_summary(summary,step)\n",
    "    summary_writer.flush()\n",
    "    \n",
    "    #Printing an overwiew\n",
    "    if (step % 1000 == 0):\n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "        print(\"Minibatch accuracy: %.2f%%\" % (acc*100))\n",
    "        print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "        print('Duration: %.3f sec' % duration)\n",
    "        #print_test_accuracy()\n",
    "        \n",
    "  #after the loop compair our model with the test dataset    \n",
    "  print(\"Test accuracy: %.1f%%\" % \\\n",
    "    accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "\n",
    "#subprocess.call(['speech-dispatcher'])        \n",
    "#subprocess.call(['spd-say', '\"over\"'])\n",
    "general_duration = time.time() - initial_time\n",
    "sec = timedelta(seconds=int(general_duration))\n",
    "d_time = datetime(1,1,1) + sec\n",
    "print(' ')\n",
    "print('The duration of the whole training with % s steps is %.2f seconds,'\\\n",
    "      % (num_steps,general_duration))\n",
    "print(\"which is equal to:  %d:%d:%d:%d\" % (d_time.day-1, d_time.hour, d_time.minute, d_time.second), end='')\n",
    "print(\" (DAYS:HOURS:MIN:SEC)\")\n",
    "print(' ')\n",
    "print(log_path)\n",
    "#!tensorboard --logdir=!!!copy log_path here!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=logs/17-04-2017_15-29-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Com os valores \n",
    "\n",
    "#batch_size = 128\n",
    "#patch_size = 6\n",
    "#filters_1 = 16\n",
    "#filters_2 = 32\n",
    "#hidden_nodes_1 = 4000\n",
    "#hidden_nodes_2 = 2000\n",
    "#hidden_nodes_3 = 1000\n",
    "\n",
    "#obtive apenas -> Test accuracy: 96.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
